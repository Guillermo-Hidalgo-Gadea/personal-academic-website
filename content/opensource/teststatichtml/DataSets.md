# Datasets

This short collection of datasets will help you get your hands dirty with actual examples in animal behavior! The videos provided serve the purpose of getting started with animal tracking software and data analysis, but do not cover entire experiments necessary for appropriate statistical analysis.

The following datasets were kindly provided as open source material by the authors and developers mentioned below, as well as by colleagues from the Biopsychology department at the Ruhr-University Bochum. Please **refrain from any misuse** of this content. Consult with the lecturer before sharing any material on social media.

## Shared Cloud Space

The data used in the exercises and hands on tutorials can be downloaded from this shared cloud directory on **Sciebo:** [https://ruhr-uni-bochum.sciebo.de/s/U319df4P4Lq4WJh](https://ruhr-uni-bochum.sciebo.de/s/U319df4P4Lq4WJh)

## Mouse bottom view for VAME demo by [Kevin Luxem](https://github.com/LINCellularNeuroscience/VAME#getting-started)

Freely behaving mice in open field exploration experiment. Mice were placed in the center of a circular area of transparent Plexiglas floor with diameter of 50 cm surrounded by a transparent Plexiglas wall with height of 50 cm. Mouse behavior was recorded by a CMOS camera (Basler acA2000-165umNIR) equipped with wide angle lens (CVO GM24514MCN, Stemmer Imaging) that was placed centrally 35 cm below the arena. Three infrared light sources (LIU780A, Thorlabs) were placed 70 cm away from the center, providing homogeneous illumination of the recording arena from below. All recordings were performed at dim room light conditions.

**Luxem, K., Fuhrmann, F., Kürsch, J., Remy, S., & Bauer, P. (2020). Identifying Behavioral Structure from Deep Variational Embeddings of Animal Motion. https://doi.org/10.1101/2020.05.14.095430**

```{toggle}
<div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><figure style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%; margin-block-end: 0; margin-block-start: 0; margin-inline-start: 0; margin-inline-end: 0;" ><iframe src="https://media.publit.io/file/demo-mouse.mp4" scrolling="no" style="border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute; overflow:hidden;" allowfullscreen=""></iframe></figure></div></div>
```

## Fly data for 3D analysis by [Pavan Ramdya](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/PKKXOE)

Experiments were performed in the late morning or early afternoon inside a dark imaging chamber. An adult female animal 2–3 days-post-eclosion, was mounted onto a custom stage and allowed to acclimate for 5 min on an air-supported spherical treadmill (Chen et al., 2018). Optogenetic stimulation was performed using a 617 nm LED (Thorlabs, Newton, NJ) pointed at the dorsal thorax through a hole in the stage, and focused with a lens (LA1951, 01" f = 25.4 mm, Thorlabs, Newton, NJ). Tethered flies were otherwise allowed to behave spontaneously.
We positioned seven Basler acA1920-155um cameras (FUJIFILM AG, Niederhaslistrasse, Switzerland) 94 mm away from the tethered fly, resulting in a circular camera network with the animal in the center.

**Günel, S., Rhodin, H., Morales, D., Campagnolo, J., Ramdya, P., & Fua, P. (2019). DeepFly3D, a deep learning-based approach for 3D limb and appendage tracking in tethered, adult Drosophila. ELife, 8, e48571. https://doi.org/10.7554/eLife.48571**

```{toggle}
<div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><figure style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%; margin-block-end: 0; margin-block-start: 0; margin-inline-start: 0; margin-inline-end: 0;" ><iframe src="https://media.publit.io/file/demo-fly.mp4" scrolling="no" style="border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute; overflow:hidden;" allowfullscreen=""></iframe></figure></div></div>
```

## Pigeon in Skinnerbox for 3D analysis by [Guillermo Hidalgo Gadea](https://www.bio.psy.ruhr-uni-bochum.de/members_guillermo.html)

A single pigeon was recorded in a Skinnerbox for a short habituation period of 5 minutes. Six synchronized cameras (FLIR BFS) were mounted on the four upper corners of the box and in the two lower corners of the from side. The pigeon did not perform any specific task during the recording.

```{toggle}
<div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><figure style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%; margin-block-end: 0; margin-block-start: 0; margin-inline-start: 0; margin-inline-end: 0;" ><iframe src="https://media.publit.io/file/demo_pigeon_skinnerbox.mp4" scrolling="no" style="border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute; overflow:hidden;" allowfullscreen=""></iframe></figure></div></div>
```

## Pigeon in Arena for 3D analysis by [Mengmeng Li](https://www.bio.psy.ruhr-uni-bochum.de/members_mengmeng.html)

A single pigeon was recorded in a hexagonal arena for a 17 minute session in an open field exploration experiment. Six synchronized cameras (FLIR BFS) were mounted on the upper corners of the arena at 180cm from the ground. The pigeon did not perform any specific task during the recording.

```{toggle}
<div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><figure style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%; margin-block-end: 0; margin-block-start: 0; margin-inline-start: 0; margin-inline-end: 0;" ><iframe src="https://media.publit.io/file/Demo-Pigeon-Arena.mp4" scrolling="no" style="border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute; overflow:hidden;" allowfullscreen=""></iframe></figure></div></div>
```

## Pigeon top view by [Neslihan Wittek](https://www.bio.psy.ruhr-uni-bochum.de/members_neslihan.html)

A single pigeon was recorded in a rectangular box separated by a clear plexiglas screen. The pigeon had continuous access to food and was recorded from the front and from top view. The pigeon did not perform any specific task during the recording.

```{toggle}
<div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><figure style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%; margin-block-end: 0; margin-block-start: 0; margin-inline-start: 0; margin-inline-end: 0;" ><iframe src="https://media.publit.io/file/demo_pigeon_topview.mp4" scrolling="no" style="border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute; overflow:hidden;" allowfullscreen=""></iframe></figure></div></div>
```

## Human Facial Expression for 3D analysis by [Guillermo Hidalgo Gadea](https://www.bio.psy.ruhr-uni-bochum.de/members_guillermo.html)

Six subjects were recorded for up to 60 seconds in a synchronized multi-view setting with six cameras (FLIR BFS). Subjects were instructed to display a short sequence of facial expressions of their choice for training purposes.

```{toggle}
<div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><figure style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%; margin-block-end: 0; margin-block-start: 0; margin-inline-start: 0; margin-inline-end: 0;" ><iframe src="https://media.publit.io/file/rTSGjBMq.mp4" scrolling="no" style="border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute; overflow:hidden;" allowfullscreen=""></iframe></figure></div></div>
```

## Individual data collection

1) You are welcome to perform your own data collection and use any video data you may already have. Any (relatively) modern smartphone or action camera will be sufficient to record a few short videos of animals in the wild. Please be careful to **respect the privacy of bystanders** when filming in public.

2) There are some great open source initiatives you could check out that share video repositories of animal behavior data such as [OpenBehavior](https://edspace.american.edu/openbehavior/video-repository/video-repository-2/). Additionally, more and more authors make their video data partially available.  

3) You can also gather video material from online sources like youtube with [Youtube-dl](https://youtube-dl.org/). Please **handle with care**. Downloaded videos should be used only for educational purposes and are not to be distributed.

    In your terminal execute:
    * ```pip install youtube_dl```
    * ```cd Downloads```
    * ```youtube-dl 'https://www.youtube.com/watch?v=7j6mGVDfTHM' -f 'bestvideo[ext=mp4]/best[ext=mp4]/best'```
