---
title: S118924 Tracking Animal Behavior – Block seminar 
subtitle: 

# Summary for listings and search engines
summary: New advances in computer vision allow to measure animal behavior.

# Link this post with a project
projects: []

# Date published
date: "2021-10-04T00:00:00Z"

# Date updated
lastmod: ""

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

diagram: true

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: 
  focal_point: ""
  placement: 2
  preview_only: false

authors:
- admin

tags:


categories:

---


## Description
New advances in computer vision and machine learning have changed the way we measure spatiotemporal dynamics of animal movement from video data. But do we really understand Animal Behavior? This hands-on seminar will introduce new advances in the field of computational neuroethology and teach you how to use animal tracking software such as **DeepLabCut** (Mathis et al., 2018) and **BORIS** (Friard et al., 2016) to analyze animal behavior. We will learn basic python skills for data analysis as well as state-of-the-art computer vision techniques to analyze video data. You will work on individual projects to gain practical experience and will end discussing the boundaries of what constitutes behavior. From mere location in space, to body pose, movement and goal-orientedness.


## Expectations
Programming skills are not necessary, but technical affinity and basic computer skills will be advantageous. The course language may be either English or German, depending on students’ background. The Block seminar will consist of one introductory session and six seminar days, grouped in three consecutive blocks. The final schedule will be discussed on Friday, October 22nd, 2021. The course will consist of lectures, discussions, group improvs and hands on exercises. Group improvs are an active learning strategy consisting of short (unprepared) presentations of ongoing group projects. The seminar will not be graded, but active participation and classroom interaction is expected. 


## Contents
Introduction, Fr. 22.10.2021 2pm
-	Lecture: About me and Syllabus
-	Discussion: Scheduling
-	Lecture: Presentation of datasets
-	Discussion: Project assignment

Block 1, day 1
-	Lecture: What is behavior and what does it mean for psychologists?
-	Group improv: Project proposal, hypotheses, and operationalization
-	Lecture: How can we measure animal behavior? 
-	Hands on: Installing and scoring in BORIS

Block 1, day 2
-	Discussion: Recap measuring behavior and BORIS
-	Lecture: Intro and how to use DeepLabCut
-	Hands on: Dummy DeepLabCut project
-	Group improv: Updated project proposal

Homework: Own data collection (if necessary)

Block 2, day 3
-	Discussion: Recap DeepLabCut workflow
-	Lecture: Recent advances in computational ethology 
-	Group improv: Methods, and analysis
-	Hands on: DeepLabCut projects (data management)

Block 2, day 4
-	Discussion: DeepLabCut Troubleshooting
-	Hands on: DeepLabCut projects (labeling)

Individual appointments (if necessary)
-	Training GLC model with GPU
-	Analyzing videos with GPU

Block 3, day 5
-	Discussion: Recap DeepLabCut troubleshooting
-	Group improv: DeepLabCut results
-	Lecture: Introduction to time series analysis 
-	Hands on: Kinematic analysis and unsupervised ML in python (scripts provided)

Block 3, day 6
-	Hands on: Data analysis
-	Hands on: Prepare final presentation 
-	Group improv: Hypothesis, methods, and results
-	Discussion: Pros and cons of DeepLabCut



## References and Recommended Literature

- Friard, O., & Gamba, M. (2016). BORIS: a free, versatile open‐source event‐logging software for video/audio coding and live observations. Methods in Ecology and Evolution, 7(11), 1325–1330. https://doi.org/10.1111/2041-210X.12584

- Lauer, J., Zhou, M., Ye, S., Menegas, W., Nath, T., Rahman, M. M., Di Santo, V., Soberanes, D., Feng, G., Murthy, V. N., Lauder, G., Dulac, C., Mathis, M. W., & Mathis, A. (2021). Multi-animal pose estimation and tracking with DeepLabCut [Preprint]. Animal Behavior and Cognition. https://doi.org/10.1101/2021.04.30.442096

- Mathis, A., Mamidanna, P., Cury, K. M., Abe, T., Murthy, V. N., Mathis, M. W., & Bethge, M. (2018). DeepLabCut: Markerless pose estimation of user-defined body parts with deep learning. Nature Neuroscience, 21(9), 1281–1289. https://doi.org/10.1038/s41593-018-0209-y

- Mathis, A., Schneider, S., Lauer, J., & Mathis, M. W. (2020). A Primer on Motion Capture with Deep Learning: Principles, Pitfalls, and Perspectives. Neuron, 108(1), 44–65. https://doi.org/10.1016/j.neuron.2020.09.017

- Mathis, M. W., & Mathis, A. (2020). Deep learning tools for the measurement of animal behavior in neuroscience. Current Opinion in Neurobiology, 60, 1–11. https://doi.org/10.1016/j.conb.2019.10.008

- Nath, T., Mathis, A., Chen, A. C., Patel, A., Bethge, M., & Mathis, M. W. (2019). Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nature Protocols, 14(7), 2152–2176. https://doi.org/10.1038/s41596-019-0176-0




*Let me know on [Twitter](https://twitter.com/G_HidalgoGadea) if you found this guide useful or would like to have a more detailed discussion on any of the methods used above.*